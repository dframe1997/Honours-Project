from newspaper import Article
import nltk
import flask
import os
from nltk.corpus import treebank
from nltk.tokenize import sent_tokenize
from nltk.corpus.reader import ChunkedCorpusReader
from nltk.tree import Tree
from flask import render_template, url_for, request, redirect, abort, json, flash
import sys

sys.path.insert(0, '../../../perkeleyparser')

from BerkeleyParser import parser

app = flask.Flask(__name__)
app.config["DEBUG"] = True

nltk.data.path.append(r"D:\Users\David\Documents\Work\University\Year 4\Honours\NLTK")

berkeleyPath = "../../../berkeleyparser/berkeleyParser-1.7.jar"
grammarPath = "../../../berkeleyparser/eng_sm6.gr"

prepositionSearchDepth = 6 #2(60%) #3(70%) #4(57.81%) #5(51.39%) #7(24.8%)
depthIncreaseThreshold = 10

class SentenceObject:
    text = ""
    tokens = []
    tagged = []
    entities = []
    periodic = False

def cls():
    n = 0
    while n < 100:
        print("\n")
        n = n + 1

def filter(tree):
        child_nodes = [child.label() for child in tree if isinstance(child, nltk.Tree)]
        return  (tree.label() == 'VP') and ('S' in child_nodes)

def openFile(fileLocation, debug):
    inputFile = open(fileLocation, "r")
    inputContent = ""
    if inputFile.mode == 'r':
        inputContent = inputFile.read()
    
    if(debug): 
        print("File opened successfully. Attempting to detect periodic sentences...")
    
    if inputContent == "":
        print("ERROR: No Text found. Please add text to the file.")
    
    return inputContent

def splitSentences(text):
    #Splitting the article into sentences
    sentenceObjectList = []
    sentenceTextList = sent_tokenize(text)
    for sentenceText in sentenceTextList:
        sentenceObject = SentenceObject()

        sentenceObject.text = sentenceText

        sentenceObject.tokens = nltk.word_tokenize(sentenceText)

        sentenceObject.tagged = nltk.pos_tag(sentenceObject.tokens)
        #output += tagged[0:6]

        sentenceObject.entities = nltk.chunk.ne_chunk(sentenceObject.tagged)

        #tree = [subtree for tree in treebank.parsed_sents() for subtree in tree.subtrees(filter)]
        #print tree

        #from nltk.corpus import treebank
        #t = treebank.parsed_sents('wsj_0001.mrg')[0]
        #entities.draw()
        sentenceObjectList.append(sentenceObject)
    return sentenceObjectList

def startingWords(sentence, debug):
    #startingFile = open("Dataset/Keywords/StartingWords.txt", "r")
    #startingWords = []
    #if startingFile.mode == 'r':
    #    startingWords = startingFile.read()
    #    if(debug == True): print("Attempting to match keywords...")
    #    for word in startingWords.split(","):
    #        if sentence.text.startswith(word):
    #            return True
    #    return False   
    for index in range(prepositionSearchDepth):
        if sentence.tagged[index][1] == "IN": #IN represents prepositions or 'subordinating conjunctions' which are often found at the start of a subordinate clause and therefore a periodic sentence
            return True
    return False       

def treeShape(sentence, debug):
    if sentence.entities.height() < 3:
        print(sentence.entities)
        print(sentence.entities.height())
        print(len(sentence.entities.leaves()))
        return True
    else:
        return False

def treeStructure(sentence, debug):
    #Based on characterizing stylistic elements
    p = parser(berkeleyPath, grammarPath)
    treeStringWBrackets = p.parse(sentence.text)
    treeString = treeStringWBrackets[1:len(treeStringWBrackets)-1]
    p.terminate() #End the parser process to save memory
    tree = Tree.fromstring(treeString) #Turn the string generated by the parser into a tree object
    #topOfTree = tree[0:treeSearchDepth] #It's not a string - need a new way to get the top layers of tree
    #tree.draw()
    for subtree in tree.subtrees():
        h = subtree.height()
        if h == tree.height()-1: #tree height is the number of subtrees under it, so the top few layers will have the greatest height #Possibly dynamic based on length of sentence?
            if subtree.label() != "VP":
                #if any(x.label() == "S" for x in subtree.subtrees()) or any(x.label() == "SBAR" for x in subtree.subtrees()): #Should it be topOfTree or node (aka search the subtree topped by node)?
                    #return True
                if any(x.label() == "S" for x in subtree.subtrees()) or any(x.label() == "SBAR" for x in subtree.subtrees()):
                    #halfSentence = sentence.text[:len(sentence.text) // 2]
                    #subordinateWord = subtree.leaves()[0]
                    #if subordinateWord in halfSentence:
                    return True
            #else:
                #if any(x.label() == "S" for x in subtree.subtrees()) or any(x.label() == "SBAR" for x in subtree.subtrees()):
                    #return False
                    # ONLY IMPLEMENT IF NEED TO DETECT LOOSE SENTENCES
    return False

def detectPeriodic(text, debug, natureOfSentences):
    sentences = splitSentences(text)
    score = 0

    for sentence in sentences:
        if(debug == True):
            print(sentence.text)
            print(sentence.tokens)
            print(sentence.tagged)
            print(sentence.entities)
        #sentence.entities.draw()
        if startingWords(sentence, debug) or treeStructure(sentence, debug):
            sentence.periodic = True
            if natureOfSentences == "Periodic":
                score += 1
            print("'" + sentence.text + "'" + " is a periodic sentence.")
        else:
            sentence.periodic = False
            if natureOfSentences == "NotPeriodic":
                score += 1
            print("'" + sentence.text + "'" + " is not a periodic sentence.")

    score = (score/sentences.__len__())*100
    return score

#Main program
#Options
def setup():
    import time
    

    testModeInput = input("Run test mode? (Default: N)")
    testMode = False

    if "y" in testModeInput.lower():
        testMode = True
    else:
        testMode = False

    debugInput = input("Show debug messages? (Default: N)")
    debug = False

    if "y" in debugInput.lower():
        debug = True
    else:
        debug = False

    start = time.time()

    if testMode:
        inputContent = openFile("Dataset/Periodic.txt", debug)
        cls()
        score = detectPeriodic(inputContent, debug, "Periodic") #The first test will check the periodic sentences
        print(str(score) + "% of periodic sentences correctly identified.")
        print("_________________________________________________")
        inputContent = openFile("Dataset/NotPeriodic.txt", debug)
        score = detectPeriodic(inputContent, debug, "NotPeriodic") #The first test will check the periodic sentences
        print(str(score) + "% of non-periodic sentences correctly identified.")
    else:
        fileLocation = input("Please type the filepath for the text you want to analyse. To use the default, simply press enter.")
        if fileLocation == "":
            fileLocation = "Input.txt"
        inputContent = openFile(fileLocation, debug)
        cls()
        detectPeriodic(inputContent, debug, "Unknown") #We don't know the nature of the sentences

    end = time.time()
    print("Run time: " + str(end - start) + " seconds")
    input("Press Enter to continue...")
    p.terminate()
setup()

